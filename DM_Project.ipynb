{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1D7AD4Tw1WQgKF2Uqo1YiAHWs8BTXDk03",
      "authorship_tag": "ABX9TyO/Ssd5qnZJ/3CJcy7wyhsl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgambone3/CSC6740_Data_Mining_Project/blob/main/DM_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3sWdJUOSRJz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.utils import resample\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Preprocessing"
      ],
      "metadata": {
        "id": "3Sbj6AWu7Bwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and View Data\n",
        "Drop unnecessary columns pertaining to histogram results, which aren't typically a part of CTG results. "
      ],
      "metadata": {
        "id": "NG_TVXvK6c66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DM_Project/fetal_health.csv')\n",
        "feat = data[['baseline value', \n",
        "              'accelerations', \n",
        "              'fetal_movement',\n",
        "              'uterine_contractions', \n",
        "              'light_decelerations', \n",
        "              'severe_decelerations',\n",
        "              'prolongued_decelerations', \n",
        "              'abnormal_short_term_variability',\n",
        "              'mean_value_of_short_term_variability',\n",
        "              'mean_value_of_long_term_variability',\n",
        "              'percentage_of_time_with_abnormal_long_term_variability',\n",
        "              'fetal_health']]\n",
        "feat = feat.rename(columns={'percentage_of_time_with_abnormal_long_term_variability':'percent_time_abnormal_long_variability'})\n",
        "data.shape\n",
        "feat.shape"
      ],
      "metadata": {
        "id": "HirO1qrKSVQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dfcb27-ee20-404b-8ae9-b8cabcaa8a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2126, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign feature and target values, X and y, respectively.\n"
      ],
      "metadata": {
        "id": "Avlk4QBv0u5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = feat[['baseline value', \n",
        "          'accelerations', \n",
        "          'fetal_movement',\n",
        "          'uterine_contractions', \n",
        "          'light_decelerations', \n",
        "          'severe_decelerations',\n",
        "          'prolongued_decelerations', \n",
        "          'abnormal_short_term_variability',\n",
        "          'mean_value_of_short_term_variability',\n",
        "          'mean_value_of_long_term_variability',\n",
        "          'percent_time_abnormal_long_variability']]\n",
        "y = feat[['fetal_health']]"
      ],
      "metadata": {
        "id": "fCrBERtcUftq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat.describe().T"
      ],
      "metadata": {
        "id": "izPD1hWO_Plh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat.info()"
      ],
      "metadata": {
        "id": "dvV5Pxbtq0rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Normalization "
      ],
      "metadata": {
        "id": "_vzp1zGI8eyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale data with standard scalar\n",
        "sc = StandardScaler().set_output(transform='pandas')\n",
        "scaled = sc.fit(X).transform(X)"
      ],
      "metadata": {
        "id": "itZNmPihAcIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dimensionality Reduction - Principal Component Analysis\n"
      ],
      "metadata": {
        "id": "By0CLp0UR96P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(scaled)\n",
        "d = {'Feature':scaled.columns.values, 'PCA Variance Ratio':pca.explained_variance_ratio_}\n",
        "pca_info = pd.DataFrame(data=d)\n",
        "l=[]\n",
        "\n",
        "for z in range(1, len(pca_info['PCA Variance Ratio']) + 1):\n",
        "  l.append(sum(pca_info['PCA Variance Ratio'].iloc[:z]))\n",
        "\n",
        "pca_info['Sum PCA Variance'] = l\n",
        "display(pca_info)"
      ],
      "metadata": {
        "id": "2voDIfDMBfzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_pca = pca.transform(scaled)\n",
        "var_ratio = pca_info['PCA Variance Ratio']\n",
        "\n",
        "x=range(0, len(var_ratio))\n",
        "plt.bar(x, var_ratio, color='lightseagreen')\n",
        "plt.ylabel('Variance (%)')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.xticks(x, ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11'])\n",
        "plt.ylim([0,1])\n",
        "plt.title('Principal Component Variance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mnMEVctsCZQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Data Analysis"
      ],
      "metadata": {
        "id": "scTRYkNO8ooT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier Distribution"
      ],
      "metadata": {
        "id": "ghGpWz6e8ytI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['1.0 - Normal', '2.0 - Suspect', '3.0 - Pathological']\n",
        "sns.countplot(data, x='fetal_health', palette='GnBu', label=labels)\n",
        "plt.title('Count Plot of Classifiers')\n",
        "plt.xlabel('Fetal Health')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(data['fetal_health'].value_counts())"
      ],
      "metadata": {
        "id": "FGqzP86-ihCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation Matrix"
      ],
      "metadata": {
        "id": "aTzEIFtk83OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = round(feat.corr(), 2)\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "# axes = fig.subplots()\n",
        "\n",
        "sns.heatmap(corr, vmin=0, vmax=1, annot=True, cmap='GnBu')\n",
        "\n",
        "plt.title('Correlation Matrix of Fetal Health Indicators')\n",
        "plt.xticks(ha='right', rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PiBfur0sz8TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View Data Distribution - Box Plots"
      ],
      "metadata": {
        "id": "bRCLIHnY9OCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(20,15))\n",
        "axes = fig.subplots(3,4)\n",
        "i = 0\n",
        "j = 0\n",
        "for col in feat[:-2]:\n",
        "  sns.boxplot(x=feat['fetal_health'], \n",
        "              y = feat[col], \n",
        "              data=feat, \n",
        "              ax=axes[i,j], \n",
        "              palette='GnBu')\n",
        "  axes[i,j].set_title(f'{col} Box Plot')\n",
        "  i+=1\n",
        "  j+=1\n",
        "  if j == 4: j=0\n",
        "  if i == 3: i=0\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YJj74E6I-UVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(20,15))\n",
        "axes = fig.subplots(3,4)\n",
        "i = 0\n",
        "j = 0\n",
        "for col in feat[:-2]:\n",
        "  sns.histplot(data=feat,\n",
        "                x=feat[col], \n",
        "                hue=feat['fetal_health'],\n",
        "                stat='frequency',\n",
        "                palette='crest',\n",
        "                ax=axes[i,j],)\n",
        "  axes[i,j].set_title(f'{col} Histogram')\n",
        "  i+=1\n",
        "  j+=1\n",
        "  if j == 4: j=0\n",
        "  if i == 3: i=0\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b2jEq57r9XQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax = MinMaxScaler(feature_range=(0,1)).set_output(transform='pandas')\n",
        "range_scaled = minmax.fit_transform(feat)\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "sns.boxplot(range_scaled,\n",
        "            palette='GnBu')\n",
        "plt.title('Normalized Feature Box Plots')\n",
        "plt.xticks(ha='right',rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xkg2cp0h2Xqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Model Evaluation"
      ],
      "metadata": {
        "id": "LfCePbyfKkxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "Ufl4ErRsGTf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler().set_output(transform='pandas')\n",
        "X_temp = feat.iloc[:, :-1]\n",
        "X = sc.fit(X_temp).transform(X_temp).values\n",
        "y = feat.iloc[:, -1].values\n",
        "sss = StratifiedShuffleSplit(n_splits=2, \n",
        "                           train_size=0.8, \n",
        "                           test_size=0.2, \n",
        "                           random_state=1234)\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
        "  X_train = X[train_index]\n",
        "  y_train = y[train_index]\n",
        "\n",
        "  X_test = X[test_index]\n",
        "  y_test = y[test_index]\n",
        "print(X_train.shape)\n",
        "\n",
        "label_binarizer = LabelBinarizer().fit(y_train)\n",
        "y_onehot_test = label_binarizer.transform(y_test) # for ROC curves"
      ],
      "metadata": {
        "id": "md2ZGfXLDZwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e369f740-dc17-4ea9-8f8d-28dbd4b4494d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1700, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_split_results(data, param_dict, model_name):\n",
        "  data = data.drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
        "                            'mean_test_score', 'std_test_score', 'std_train_score',\n",
        "                            'rank_test_score', 'split0_train_score', 'split1_train_score',\n",
        "                            'split2_train_score', 'split3_train_score', 'split4_train_score',\n",
        "                            'split5_train_score', 'split6_train_score', 'split7_train_score',\n",
        "                            'split8_train_score', 'split9_train_score', 'mean_train_score',])\n",
        "  \n",
        "  fig = plt.figure(figsize=(15,5))\n",
        "  axes = fig.subplots(1, len(param_dict), sharey=True) \n",
        "  \n",
        "  for i, (param_name, param_range) in enumerate(param_dict.items()):\n",
        "    fig.suptitle(f'10-Fold Cross-Validation Results for {model_name} Hyper-Parameters', fontsize=15)\n",
        "    grouped = data.groupby(by=f'param_{param_name}').agg('mean').T\n",
        "    grouped.index = np.arange(1, len(grouped) + 1)\n",
        "\n",
        "    sns.lineplot(grouped, palette='ocean', ax=axes[i])\n",
        "    axes[i].set(title=param_name, \n",
        "                xlabel='Fold', \n",
        "                ylabel='Score', \n",
        "                visible=True)\n",
        "    axes[i].set_xticks(grouped.index)\n",
        "    axes[i].legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "vSB817WU8MMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_ROC_curve(mod, XX_train, yy_train, XX_test):\n",
        "  fig = plt.figure(figsize=(15,5))\n",
        "  axes=fig.subplots(1,2)\n",
        "  ConfusionMatrixDisplay.from_predictions(y_true=y_test, \n",
        "                                          y_pred=pred,\n",
        "                                          cmap='GnBu', \n",
        "                                          ax=axes[0])\n",
        "  axes[0].set(title=f'{model_names[i]} Confusion Matrix')\n",
        "  try:\n",
        "    y_score = mod.fit(XX_train, yy_train).predict_proba(XX_test)\n",
        "  except:\n",
        "    m = CalibratedClassifierCV(mod) \n",
        "    m.fit(XX_train, yy_train)\n",
        "    y_score = m.predict_proba(XX_test)\n",
        "\n",
        "  print(classification_report(y_test, pred))\n",
        "  RocCurveDisplay.from_predictions(y_onehot_test.ravel(),\n",
        "                                    y_score.ravel(),\n",
        "                                    name=\"Micro-Average One-vs-Rest\",\n",
        "                                    color=\"navy\",\n",
        "                                    ax=axes[1])\n",
        "  axes[1].set(title=f'{model_names[i]} ROC Curve', xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
        "  axes[1].plot([0, 1], [0, 1], label=\"chance level (AUC = 0.5)\", color='lightgreen', linestyle='--')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "r4oSh635m-_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(mod):\n",
        "  X_train_corr = X_temp[['abnormal_short_term_variability', 'percent_time_abnormal_long_variability']]\n",
        "\n",
        "  mod.fit(X_train_corr, y)\n",
        "\n",
        "  disp = DecisionBoundaryDisplay.from_estimator(mod,\n",
        "                                                X_train_corr,\n",
        "                                                response_method=\"predict\",\n",
        "                                                alpha=0.5,\n",
        "                                                xlabel='Abnormal Short Term Variability',\n",
        "                                                ylabel='Percent Time Abnormal Long Variability',\n",
        "                                                cmap='GnBu')\n",
        "\n",
        "  decision_function = mod.decision_function(X_train_corr)\n",
        "  support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\n",
        "  support_vectors = X_train_corr.values[support_vector_indices]\n",
        "\n",
        "  scat = plt.scatter(X_train_corr.iloc[:, 0], \n",
        "                      X_train_corr.iloc[:, 1], \n",
        "                      c=y, \n",
        "                      edgecolors=\"k\", \n",
        "                      cmap='GnBu')\n",
        "  plt.title('Decision Boundaries for Polynomial Support Vector Machine')\n",
        "\n",
        "  handles, labels = scat.legend_elements()\n",
        "  labels = ['1.0 - Normal', '2.0 - Suspect', '3.0 - Pathological']\n",
        "  plt.legend(handles=handles, labels=labels)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "R14fCN2FsItf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['Decision Tree',\n",
        "              'Support Vector Machine',\n",
        "              'Gradient Boost',\n",
        "              'k-Nearest Neighbors',\n",
        "              'Logistic Regression']\n",
        "\n",
        "dt = DecisionTreeClassifier(class_weight='balanced')\n",
        "\n",
        "svm = SVC(class_weight='balanced')\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "logreg = LogisticRegression(class_weight='balanced')\n",
        "\n",
        "models = [dt, svm, gb, knn, logreg]"
      ],
      "metadata": {
        "id": "3EebsgAFDZoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_params = {'criterion':('gini', 'entropy', 'log_loss'),\n",
        "             'max_features':('auto', 'sqrt', 'log2'),\n",
        "             'splitter':('random', 'best')}\n",
        "\n",
        "svm_params = {'C':(1.0, 1.25, 1.5, 1.75, 2.0),\n",
        "              'kernel':('linear', 'rbf', 'poly', 'sigmoid'),\n",
        "              'degree':(1,2,3,4,5)}\n",
        "\n",
        "gb_params = {'criterion':('friedman_mse', 'squared_error'),\n",
        "             'loss':('log_loss', 'deviance'),\n",
        "             'n_estimators':(100, 150, 200, 250)}\n",
        "\n",
        "knn_params = {'metric':('manhattan','euclidean','cosine'),\n",
        "              'weights':('uniform', 'distance'),\n",
        "              'n_neighbors':(3, 5, 7, 9)}\n",
        "\n",
        "logreg_params = {'C':(1.0, 1.25, 1.5, 1.75, 2.0),\n",
        "                 'penalty': ('l1', 'l2'), \n",
        "                 'solver': ['liblinear']}\n",
        "\n",
        "param_grids = [dt_params, svm_params, gb_params, knn_params, logreg_params]"
      ],
      "metadata": {
        "id": "xbxtvDn0bDXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(models)):\n",
        "  grid = GridSearchCV(estimator=models[i], \n",
        "                      param_grid=param_grids[i],\n",
        "                      scoring='f1_weighted',\n",
        "                      return_train_score=True,\n",
        "                      cv=10)\n",
        "  grid.fit(X_train, y_train)\n",
        "  results = pd.DataFrame(grid.cv_results_)#.loc[:,'params':'split9_test_score']\n",
        "  plot_split_results(results, param_grids[i], model_names[i])\n",
        "\n",
        "  print(f'\\n    -------  {type(models[i]).__name__}  -------  ')\n",
        "  print(f'  The best estimator: {grid.best_estimator_}')\n",
        "  print(f'  The best score: {round(grid.best_score_, 4)}')\n",
        "  print(f'  The best parameters: {grid.best_params_}\\n')\n",
        "  # display(results[['params', 'rank_test_score', \n",
        "  #                 'mean_test_score', 'std_test_score', \n",
        "  #                 'mean_train_score', 'std_train_score']])\n",
        "  \n",
        "  model = grid.best_estimator_\n",
        "  pred = grid.predict(X_test)\n",
        "\n",
        "  plot_ROC_curve(model, X_train, y_train, X_test)\n",
        "  if model_names[i] == 'Support Vector Machine':\n",
        "    plot_decision_boundary(model)"
      ],
      "metadata": {
        "id": "mZpaVVemIbNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Model Interpretation"
      ],
      "metadata": {
        "id": "6zxwn5S68P5V"
      }
    }
  ]
}