{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "mount_file_id": "1s1hCS3YzzsfZuJagF0laQQKLxtpD-w6J",
      "authorship_tag": "ABX9TyMAew6dG+XNrsNTj2uSc8zv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgambone3/CSC6740_Data_Mining_Project/blob/main/Data_Mining_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZwZtZNxVMNF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.utils import resample\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DM_Project/fetal_health.csv')\n",
        "feat = data[['baseline value', \n",
        "              'accelerations', \n",
        "              'fetal_movement',\n",
        "              'uterine_contractions', \n",
        "              'light_decelerations', \n",
        "              'severe_decelerations',\n",
        "              'prolongued_decelerations', \n",
        "              'abnormal_short_term_variability',\n",
        "              'mean_value_of_short_term_variability',\n",
        "              'mean_value_of_long_term_variability',\n",
        "              'percentage_of_time_with_abnormal_long_term_variability',\n",
        "              'fetal_health']]\n",
        "feat = feat.rename(columns={'percentage_of_time_with_abnormal_long_term_variability':'percent_time_abnormal_long_variability'})\n",
        "data.shape"
      ],
      "metadata": {
        "id": "T48VBTCkV9rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = feat[['baseline value', \n",
        "          'accelerations', \n",
        "          'fetal_movement',\n",
        "          'uterine_contractions', \n",
        "          'light_decelerations', \n",
        "          'severe_decelerations',\n",
        "          'prolongued_decelerations', \n",
        "          'abnormal_short_term_variability',\n",
        "          'mean_value_of_short_term_variability',\n",
        "          'mean_value_of_long_term_variability',\n",
        "          'percent_time_abnormal_long_variability']]\n",
        "y = feat[['fetal_health']]"
      ],
      "metadata": {
        "id": "uCjBkYvAV_Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat.describe().T"
      ],
      "metadata": {
        "id": "Lbn4cpVoWxbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat.info()"
      ],
      "metadata": {
        "id": "224UIBP2WzXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale data with standard scalar\n",
        "sc = StandardScaler().set_output(transform='pandas')\n",
        "scaled = sc.fit(X).transform(X)"
      ],
      "metadata": {
        "id": "imW31VLlW0vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(scaled)\n",
        "d = {'Feature':scaled.columns.values, 'PCA Variance Ratio':pca.explained_variance_ratio_}\n",
        "pca_info = pd.DataFrame(data=d)\n",
        "l=[]\n",
        "\n",
        "for z in range(1, len(pca_info['PCA Variance Ratio']) + 1):\n",
        "  l.append(sum(pca_info['PCA Variance Ratio'].iloc[:z]))\n",
        "\n",
        "pca_info['Sum PCA Variance'] = l\n",
        "display(pca_info)"
      ],
      "metadata": {
        "id": "k0Cb4XLTW3ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_pca = pca.transform(scaled)\n",
        "var_ratio = pca_info['PCA Variance Ratio']\n",
        "\n",
        "x=range(0, len(var_ratio))\n",
        "plt.bar(x, var_ratio, color='lightseagreen')\n",
        "plt.ylabel('Variance (%)')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.xticks(x, ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11'])\n",
        "plt.ylim([0,1])\n",
        "plt.title('Principal Component Variance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JnIKD4JeW91M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['1.0 - Normal', '2.0 - Suspect', '3.0 - Pathological']\n",
        "sns.countplot(data, x='fetal_health', palette='GnBu', label=labels)\n",
        "plt.title('Count Plot of Classifiers')\n",
        "plt.xlabel('Fetal Health')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x3IY_LGvW_Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = round(feat.corr(), 2)\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "axes = fig.subplots()\n",
        "\n",
        "sns.heatmap(corr, vmin=0, vmax=1, annot=True, cmap='GnBu')\n",
        "\n",
        "plt.title('Correlation Matrix of Fetal Health Indicators')\n",
        "plt.xticks(ha='right', rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m_LhpS9iXBAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(20,15))\n",
        "axes = fig.subplots(3,4)\n",
        "i = 0\n",
        "j = 0\n",
        "for col in feat[:-2]:\n",
        "  sns.boxplot(x=feat['fetal_health'], \n",
        "              y = feat[col], \n",
        "              data=feat, \n",
        "              ax=axes[i,j], \n",
        "              palette='GnBu')\n",
        "  axes[i,j].set_title(f'{col} Box Plot')\n",
        "  i+=1\n",
        "  j+=1\n",
        "  if j == 4: j=0\n",
        "  if i == 3: i=0\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zmWdLU_BXC2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(20,15))\n",
        "axes = fig.subplots(3,4)\n",
        "i = 0\n",
        "j = 0\n",
        "for col in feat[:-2]:\n",
        "  sns.histplot(data=feat,\n",
        "                x=feat[col], \n",
        "                hue=feat['fetal_health'],\n",
        "                stat='density',\n",
        "                palette='crest',\n",
        "                ax=axes[i,j],)\n",
        "  axes[i,j].set_title(f'{col} Histogram')\n",
        "  i+=1\n",
        "  j+=1\n",
        "  if j == 4: j=0\n",
        "  if i == 3: i=0\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gNirPDU_XEin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax = MinMaxScaler(feature_range=(0,1)).set_output(transform='pandas')\n",
        "range_scaled = minmax.fit_transform(feat)\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "sns.boxplot(range_scaled,\n",
        "            palette='GnBu')\n",
        "plt.title('Normalized Feature Box Plots')\n",
        "plt.xticks(ha='right',rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6kYZELeGXHJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "utTcC_ujXIi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler().set_output(transform='pandas')\n",
        "X_temp = feat.iloc[:, :-1]\n",
        "X = sc.fit(X_temp).transform(X_temp).values\n",
        "y = feat.iloc[:, -1].values\n",
        "sss = StratifiedShuffleSplit(n_splits=2, \n",
        "                           train_size=0.8, \n",
        "                           test_size=0.2, \n",
        "                           random_state=1234)\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
        "  X_train = X[train_index]\n",
        "  y_train = y[train_index]\n",
        "\n",
        "  X_test = X[test_index]\n",
        "  y_test = y[test_index]\n",
        "print(X_train.shape)\n",
        "\n",
        "label_binarizer = LabelBinarizer().fit(y_train)\n",
        "y_onehot_test = label_binarizer.transform(y_test) # for ROC curves"
      ],
      "metadata": {
        "id": "PyHa7iayXKBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_split_results(data, param_dict, model_name):\n",
        "  data = data.drop(columns=['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
        "                            'mean_test_score', 'std_test_score', 'std_train_score',\n",
        "                            'rank_test_score', 'split0_train_score', 'split1_train_score',\n",
        "                            'split2_train_score', 'split3_train_score', 'split4_train_score',\n",
        "                            'split5_train_score', 'split6_train_score', 'split7_train_score',\n",
        "                            'split8_train_score', 'split9_train_score', 'mean_train_score',])\n",
        "  \n",
        "  fig = plt.figure(figsize=(15,5))\n",
        "  axes = fig.subplots(1, len(param_dict), sharey=True) \n",
        "  \n",
        "  for i, (param_name, param_range) in enumerate(param_dict.items()):\n",
        "    fig.suptitle(f'10-Fold Cross-Validation Results for {model_name} Hyper-Parameters', fontsize=15)\n",
        "    grouped = data.groupby(by=f'param_{param_name}').agg('mean').T\n",
        "    grouped.index = np.arange(1, len(grouped) + 1)\n",
        "\n",
        "    sns.lineplot(grouped, palette='ocean', ax=axes[i])\n",
        "    axes[i].set(title=param_name, \n",
        "                xlabel='Fold', \n",
        "                ylabel='Score', \n",
        "                visible=True)\n",
        "    axes[i].set_xticks(grouped.index)\n",
        "    axes[i].legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "4upqy6qyXLh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_ROC_curve(mod, XX_train, yy_train, XX_test):\n",
        "  fig = plt.figure(figsize=(15,5))\n",
        "  axes=fig.subplots(1,2)\n",
        "  ConfusionMatrixDisplay.from_predictions(y_true=y_test, \n",
        "                                          y_pred=pred,\n",
        "                                          cmap='GnBu', \n",
        "                                          ax=axes[0])\n",
        "  axes[0].set(title=f'{model_names[i]} Confusion Matrix')\n",
        "  try:\n",
        "    y_score = mod.fit(XX_train, yy_train).predict_proba(XX_test)\n",
        "  except:\n",
        "    m = CalibratedClassifierCV(mod) \n",
        "    m.fit(XX_train, yy_train)\n",
        "    y_score = m.predict_proba(XX_test)\n",
        "\n",
        "  print(classification_report(y_test, pred))\n",
        "  RocCurveDisplay.from_predictions(y_onehot_test.ravel(),\n",
        "                                    y_score.ravel(),\n",
        "                                    name=\"Micro-Average One-vs-Rest\",\n",
        "                                    color=\"navy\",\n",
        "                                    ax=axes[1])\n",
        "  axes[1].set(title=f'{model_names[i]} ROC Curve', xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
        "  axes[1].plot([0, 1], [0, 1], label=\"chance level (AUC = 0.5)\", color='lightgreen', linestyle='--')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "EyTBpBv4XM4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(mod):\n",
        "  X_train_corr = X_temp[['abnormal_short_term_variability', 'percent_time_abnormal_long_variability']]\n",
        "\n",
        "  mod.fit(X_train_corr, y)\n",
        "\n",
        "  disp = DecisionBoundaryDisplay.from_estimator(mod,\n",
        "                                                X_train_corr,\n",
        "                                                response_method=\"predict\",\n",
        "                                                alpha=0.5,\n",
        "                                                xlabel='Abnormal Short Term Variability',\n",
        "                                                ylabel='Percent Time Abnormal Long Variability',\n",
        "                                                cmap='GnBu')\n",
        "\n",
        "  decision_function = mod.decision_function(X_train_corr)\n",
        "  support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\n",
        "  support_vectors = X_train_corr.values[support_vector_indices]\n",
        "\n",
        "  scat = plt.scatter(X_train_corr.iloc[:, 0], \n",
        "                      X_train_corr.iloc[:, 1], \n",
        "                      c=y, \n",
        "                      edgecolors=\"k\", \n",
        "                      cmap='GnBu')\n",
        "  plt.title('Decision Boundaries for Linear Support Vector Machine')\n",
        "\n",
        "  handles, labels = scat.legend_elements()\n",
        "  labels = ['1.0 - Normal', '2.0 - Suspect', '3.0 - Pathological']\n",
        "  plt.legend(handles=handles, labels=labels)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "wCKH3X6JXOE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = ['Decision Tree',\n",
        "              'Support Vector Machine',\n",
        "              'Gradient Boost',\n",
        "              'k-Nearest Neighbors',\n",
        "              'Logistic Regression']\n",
        "\n",
        "dt = DecisionTreeClassifier(class_weight='balanced')\n",
        "\n",
        "svm = SVC(class_weight='balanced')\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "logreg = LogisticRegression(class_weight='balanced')\n",
        "\n",
        "models = [dt, svm, gb, knn, logreg]"
      ],
      "metadata": {
        "id": "3fcDUGqfXPTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_params = {'criterion':('gini', 'entropy', 'log_loss'),\n",
        "             'max_features':('auto', 'sqrt', 'log2'),\n",
        "             'splitter':('random', 'best')}\n",
        "\n",
        "svm_params = {'C':(1.0, 1.25, 1.5, 1.75, 2.0),\n",
        "              'kernel':('linear', 'rbf', 'poly', 'sigmoid'),\n",
        "              'degree':(1,2,3,4,5)}\n",
        "\n",
        "gb_params = {'criterion':('friedman_mse', 'squared_error'),\n",
        "             'loss':('log_loss', 'deviance'),\n",
        "             'n_estimators':(100, 150, 200, 250)}\n",
        "\n",
        "knn_params = {'metric':('manhattan','euclidean','cosine'),\n",
        "              'weights':('uniform', 'distance'),\n",
        "              'n_neighbors':(3, 5, 7, 9)}\n",
        "\n",
        "logreg_params = {'C':(1.0, 1.25, 1.5, 1.75, 2.0),\n",
        "                 'penalty': ('l1', 'l2'), \n",
        "                 'solver': ['liblinear']}\n",
        "\n",
        "param_grids = [dt_params, svm_params, gb_params, knn_params, logreg_params]"
      ],
      "metadata": {
        "id": "t9ES6u6EXQvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(models)):\n",
        "  grid = GridSearchCV(estimator=models[i], \n",
        "                      param_grid=param_grids[i],\n",
        "                      scoring='f1_weighted',\n",
        "                      return_train_score=True,\n",
        "                      cv=10)\n",
        "  grid.fit(X_train, y_train)\n",
        "  results = pd.DataFrame(grid.cv_results_)#.loc[:,'params':'split9_test_score']\n",
        "  plot_split_results(results, param_grids[i], model_names[i])\n",
        "\n",
        "  print(f'\\n    -------  {type(models[i]).__name__}  -------  ')\n",
        "  print(f'  The best estimator: {grid.best_estimator_}')\n",
        "  print(f'  The best score: {round(grid.best_score_, 4)}')\n",
        "  print(f'  The best parameters: {grid.best_params_}\\n')\n",
        "  # display(results[['params', 'rank_test_score', \n",
        "  #                 'mean_test_score', 'std_test_score', \n",
        "  #                 'mean_train_score', 'std_train_score']])\n",
        "  \n",
        "  model = grid.best_estimator_\n",
        "  pred = grid.predict(X_test)\n",
        "\n",
        "  plot_ROC_curve(model, X_train, y_train, X_test)\n",
        "  if model_names[i] == 'Support Vector Machine':\n",
        "    plot_decision_boundary(model)"
      ],
      "metadata": {
        "id": "mDU6jeXPXR63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pGV2pm4oXTwz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}